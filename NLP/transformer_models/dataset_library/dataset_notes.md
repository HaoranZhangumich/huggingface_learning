# Dataset library
## loading a custom dataset
### Accept dataset format
1. csv
2. text
3. json
4. paraquet

```python
from datasets import load_dataset
### replace with data format
load_dataset('csv', data_files='my_file.csv')

```
### loading specific field for json
```python
from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")
```
- local files create DatasetDict object with a train split

```code
squad_it_dataset
Copied
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})
```
This show the number of rows and column names associated with the training set

```code
squad_it_dataset["train"][0]
```
{
    "title": "Terremoto del Sichuan del 2008",
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si Ã¨ verificato il terremoto nel Sichuan?",
                },
                ...
            ],
        },
        ...
    ],
}

- separate with train and test splits
```python
data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset
```
```code
DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})
```